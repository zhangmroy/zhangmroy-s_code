#coding:utf-8
import re
import urllib
import os
import webbrowser as web

blog_address = "http://blog.sina.com.cn/s/articlelist_1191258123_0_1.html"
page_flag = 1
#blog_content = urllib.urlopen(blog_address).read()

#用于下载有用文章的过滤器
blog_filter1 = re.compile(r'a title="(.+?\.html)')
blog_filter2 = re.compile(r'href="(.+?\.html)')

#用于找到其他博客页面的过滤器
blog_filter3 = re.compile(r'title="(.+?\.html)')
blog_filter4 = re.compile(r'a href="(.+?\.html)')



#下载当前页面的文章
def Download_recent(add):
    content = urllib.urlopen(add).read()
    address_firsttime = str(re.findall(blog_filter1,content))
    address_secondtime = re.findall(blog_filter2,address_firsttime)
    global page_flag #在函数值使用全局变量时要声明
    print "Downing Page:",page_flag
    page_flag = page_flag + 1
    flag = 1
    for i in address_secondtime:
        i_content = urllib.urlopen(i).read()
        i_filename = i[-26:]
        print 'PageDownload Success',flag
        flag = flag + 1
        #写文件
        page = open(i_filename,'w')
        page.write(i_content)
        page.close()
        

        

#提取当前页面中链接到其他页面的有效地址
def Get_link(add):
    content = urllib.urlopen(add).read()
    address_firsttime = str(re.findall(blog_filter3,content))
    address_secondtime = re.findall(blog_filter4,address_firsttime)
    return address_secondtime
    


#主函数
def Blog_Download(add):
    Download_recent(add)
    page = Get_link(add)
    flag = 2
    for p in page:
        Download_recent(p)



Blog_Download(blog_address)

